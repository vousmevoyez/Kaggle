{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading files...\n",
      "((595212, 229), (892816, 229))\n",
      "Length of dcol: 25\n",
      "((595212, 207), (892816, 237))\n",
      "xgb start...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KrystalU\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py:50: RuntimeWarning: invalid value encountered in greater\n",
      "C:\\Users\\KrystalU\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py:51: RuntimeWarning: invalid value encountered in greater\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb kfold: 1  of  5 : \n",
      "Length of dcol: 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KrystalU\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\KrystalU\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\KrystalU\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of dcol: 25\n",
      "set(['target'])\n",
      "[0]\ttrain-auc:0.514444\tvalid-auc:0.512605\ttrain-gini:0.029039\tvalid-gini:0.035007\n",
      "Multiple eval metrics have been passed: 'valid-gini' will be used for early stopping.\n",
      "\n",
      "Will train until valid-gini hasn't improved in 100 rounds.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-8340af237052>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    119\u001b[0m         \u001b[0mwatchlist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'train'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0md_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'valid'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m         xgb_model = xgb.train(params, d_train, nrounds, watchlist, early_stopping_rounds=100,\n\u001b[1;32m--> 121\u001b[1;33m                               feval=gini_xgb, maximize=True, verbose_eval=100)\n\u001b[0m\u001b[0;32m    122\u001b[0m         sub['xgb'] += xgb_model.predict(xgb.DMatrix(test.values),\n\u001b[0;32m    123\u001b[0m                                         ntree_limit=xgb_model.best_ntree_limit+50) / (kfold)\n",
      "\u001b[1;32mC:\\Users\\KrystalU\\Anaconda2\\lib\\site-packages\\xgboost-0.6-py2.7.egg\\xgboost\\training.pyc\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[0;32m    202\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 204\u001b[1;33m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[0;32m    205\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\KrystalU\\Anaconda2\\lib\\site-packages\\xgboost-0.6-py2.7.egg\\xgboost\\training.pyc\u001b[0m in \u001b[0;36m_train_internal\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[1;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m             \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\KrystalU\\Anaconda2\\lib\\site-packages\\xgboost-0.6-py2.7.egg\\xgboost\\core.pyc\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m    894\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    895\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[1;32m--> 896\u001b[1;33m                                                     dtrain.handle))\n\u001b[0m\u001b[0;32m    897\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    898\u001b[0m             \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from time import time\n",
    "from catboost import CatBoostClassifier\n",
    "import gc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from scipy.stats import randint as sp_randint\n",
    "from hyperopt import hp, tpe, STATUS_OK, Trials, fmin\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# custom objective function (similar to auc)\n",
    "def gini(y, pred):\n",
    "    g = np.asarray(np.c_[y, pred, np.arange(len(y))], dtype=np.float)\n",
    "    g = g[np.lexsort((g[:,2], -1*g[:,1]))]\n",
    "    gs = g[:,0].cumsum().sum() / g[:,0].sum()\n",
    "    gs -= (len(y) + 1) / 2.\n",
    "    return gs / len(y)\n",
    "\n",
    "def gini_xgb(pred, y):\n",
    "    y = y.get_label()\n",
    "    return 'gini', gini(y, pred) / gini(y, y)\n",
    "\n",
    "def gini_lgb(preds, dtrain):\n",
    "    y = list(dtrain.get_label())\n",
    "    score = gini(y, preds) / gini(y, y)\n",
    "    return 'gini', score, True\n",
    "\n",
    "def load_data():\n",
    "    print('loading files...')\n",
    "    train = pd.read_csv('D:/Driver/ohe_train_v2.csv')\n",
    "    test = pd.read_csv('D:/Driver/ohe_test_v2.csv')\n",
    "    print(train.shape, test.shape)\n",
    "\n",
    "    unwanted = train.columns[train.columns.str.startswith('ps_calc_')]\n",
    "    train = train.drop(unwanted, axis=1)\n",
    "    test = test.drop(unwanted, axis=1)\n",
    "    return train, test\n",
    "\n",
    "def transform(df, d_median, d_mean):\n",
    "    dcol = [c for c in df.columns if c not in ['id','target'] and 'ohe' not in c]\n",
    "    print('Length of dcol: {}'.format(len(dcol)))\n",
    "    df['ps_car_13_x_ps_reg_03'] = df['ps_car_13'] * df['ps_reg_03']\n",
    "    for c in dcol:\n",
    "        if '_bin' not in c: #standard arithmetic\n",
    "            df[c+str('_median_range')] = (df[c].values > d_median[c]).astype(np.int)\n",
    "            df[c+str('_mean_range')] = (df[c].values > d_mean[c]).astype(np.int)\n",
    "    return df\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    train, test = load_data()\n",
    "\n",
    "    start = time()\n",
    "\n",
    "    X = train.drop(['id', 'target'], axis=1)\n",
    "    features = X.columns\n",
    "    y = train['target']\n",
    "    sub = test['id'].to_frame()\n",
    "    sub['target'] = 0\n",
    "    sub['xgb'] = 0\n",
    "    sub['lgb'] = 0\n",
    "    # sub['rf'] = 0\n",
    "    test.drop('id',axis=1,inplace=True)\n",
    "\n",
    "    nrounds = 2000  # need to change to 2000\n",
    "    kfold = 5  # need to change to 5\n",
    "\n",
    "    # # rf\n",
    "    # rf = RandomForestClassifier(max_features = 0.6,\n",
    "    #                             min_samples_split = 325,\n",
    "    #                             n_estimators = 500,\n",
    "    #                             max_depth = 14,\n",
    "    #                             min_samples_leaf = 333,\n",
    "    #                             n_jobs=4,verbose=5)\n",
    "    #\n",
    "    # skf = StratifiedKFold(n_splits=kfold, random_state=2017)\n",
    "    # for i, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
    "    #     print('rf kfold: {}  of  {} : '.format(i + 1, kfold))\n",
    "    #     X_train, X_valid = X[train_index], X[test_index]\n",
    "    #     y_train, y_valid = y[train_index], y[test_index]\n",
    "    #     rf_model = rf.fit(X_train, y_train)\n",
    "    #     y_valid_pred = rf_model.predict_proba(X_valid)[:,1]\n",
    "    #     print 'Fold {}: {}'.format(i+1 ,2*roc_auc_score(y_valid, y_valid_pred)-1)\n",
    "    #     sub['sub'] += rf_model.predict_proba(test[features].values)[:,1] / (kfold)\n",
    "\n",
    "    test_median = test.median(axis=0)\n",
    "    test_mean = test.mean(axis=0)\n",
    "    test = transform(test, test_median, test_mean)\n",
    "\n",
    "    print(X.shape, test.shape)\n",
    "    # xgb\n",
    "    print('xgb start...')\n",
    "    params = {'eta': 0.025, 'max_depth': 7, 'subsample': 0.8, 'colsample_bytree': 0.4,\n",
    "              'objective': 'binary:logistic', 'eval_metric': 'auc', 'silent': True, 'max_delta_step':1.8,\n",
    "              'min_child_weight':8, 'gamma':0.65}\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=kfold, random_state=2016)\n",
    "    for i, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
    "        print('xgb kfold: {}  of  {} : '.format(i + 1, kfold))\n",
    "        X_train, X_valid = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_valid = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        d_median = X_train.median(axis=0)\n",
    "        d_mean = X_train.mean(axis=0)\n",
    "        X_train = transform(X_train, d_median, d_mean)\n",
    "        d_median = X_valid.median(axis=0)\n",
    "        d_mean = X_valid.mean(axis=0)\n",
    "        X_valid = transform(X_valid, d_median, d_mean)\n",
    "        \n",
    "        print(set(test.columns) - set(X_train.columns))\n",
    "        exit()\n",
    "        \n",
    "        d_train = xgb.DMatrix(X_train.values, y_train.values)\n",
    "        d_valid = xgb.DMatrix(X_valid.values, y_valid.values)\n",
    "        watchlist = [(d_train, 'train'), (d_valid, 'valid')]\n",
    "        xgb_model = xgb.train(params, d_train, nrounds, watchlist, early_stopping_rounds=100,\n",
    "                              feval=gini_xgb, maximize=True, verbose_eval=100)\n",
    "        sub['xgb'] += xgb_model.predict(xgb.DMatrix(test.values),\n",
    "                                        ntree_limit=xgb_model.best_ntree_limit+50) / (kfold)\n",
    "        print(sub.head())\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "    # lgb\n",
    "    print('lgb start...')\n",
    "    params = {'metric': 'auc', 'learning_rate': 0.01, 'max_depth': 10, 'max_bin': 10, 'objective': 'binary',\n",
    "              'feature_fraction': 0.8, 'bagging_fraction': 0.9, 'bagging_freq': 10, 'min_data': 500}\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=kfold, random_state=2017)\n",
    "    for i, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
    "        print('lgb kfold: {}  of  {} : '.format(i + 1, kfold))\n",
    "        X_train, X_valid = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_vaid = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        d_median = X_train.median(axis=0)\n",
    "        d_mean = X_train.mean(axis=0)\n",
    "        X_train = transform(X_train, d_median, d_mean)\n",
    "        d_median = X_valid.median(axis=0)\n",
    "        d_mean = X_valid.mean(axis=0)\n",
    "        X_valid = transform(X_valid, d_median, d_mean)\n",
    "\n",
    "        lgb_model = lgb.train(params, lgb.Dataset(X_train.values, label=y_train.values), nrounds,\n",
    "                              lgb.Dataset(X_valid.values, label=y_valid.values), verbose_eval=100,\n",
    "                              feval=gini_lgb, early_stopping_rounds=100)\n",
    "        sub['lgb'] += lgb_model.predict(test.values,\n",
    "                                        num_iteration=lgb_model.best_iteration+50) / (kfold)\n",
    "        print(sub.head())\n",
    "\n",
    "    gc.collect()\n",
    "    print(sub.head(2))\n",
    "    sub.to_csv('D:/Driver/sub25.csv',index=False)\n",
    "    print('Total time: {} mins'.format((time()-start) / 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
